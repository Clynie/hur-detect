{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copyright 2017 Paul Balanca. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"TF Extended: additional metrics.\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.contrib.framework.python.ops import variables as contrib_variables\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import nn\n",
    "from tensorflow.python.ops import state_ops\n",
    "from tensorflow.python.ops import variable_scope\n",
    "from tensorflow.python.ops import variables\n",
    "\n",
    "from tf_extended import math as tfe_math\n",
    "\n",
    "\n",
    "# =========================================================================== #\n",
    "# TensorFlow utils\n",
    "# =========================================================================== #\n",
    "def _create_local(name, shape, collections=None, validate_shape=True,\n",
    "                  dtype=dtypes.float32):\n",
    "    \"\"\"Creates a new local variable.\n",
    "    Args:\n",
    "        name: The name of the new or existing variable.\n",
    "        shape: Shape of the new or existing variable.\n",
    "        collections: A list of collection names to which the Variable will be added.\n",
    "        validate_shape: Whether to validate the shape of the variable.\n",
    "        dtype: Data type of the variables.\n",
    "    Returns:\n",
    "        The created variable.\n",
    "    \"\"\"\n",
    "    # Make sure local variables are added to tf.GraphKeys.LOCAL_VARIABLES\n",
    "    collections = list(collections or [])\n",
    "    collections += [ops.GraphKeys.LOCAL_VARIABLES]\n",
    "    return variables.Variable(\n",
    "            initial_value=array_ops.zeros(shape, dtype=dtype),\n",
    "            name=name,\n",
    "            trainable=False,\n",
    "            collections=collections,\n",
    "            validate_shape=validate_shape)\n",
    "\n",
    "\n",
    "def _safe_div(numerator, denominator, name):\n",
    "    \"\"\"Divides two values, returning 0 if the denominator is <= 0.\n",
    "    Args:\n",
    "      numerator: A real `Tensor`.\n",
    "      denominator: A real `Tensor`, with dtype matching `numerator`.\n",
    "      name: Name for the returned op.\n",
    "    Returns:\n",
    "      0 if `denominator` <= 0, else `numerator` / `denominator`\n",
    "    \"\"\"\n",
    "    return tf.where(\n",
    "        math_ops.greater(denominator, 0),\n",
    "        math_ops.divide(numerator, denominator),\n",
    "        tf.zeros_like(numerator),\n",
    "        name=name)\n",
    "\n",
    "\n",
    "def _broadcast_weights(weights, values):\n",
    "    \"\"\"Broadcast `weights` to the same shape as `values`.\n",
    "    This returns a version of `weights` following the same broadcast rules as\n",
    "    `mul(weights, values)`. When computing a weighted average, use this function\n",
    "    to broadcast `weights` before summing them; e.g.,\n",
    "    `reduce_sum(w * v) / reduce_sum(_broadcast_weights(w, v))`.\n",
    "    Args:\n",
    "      weights: `Tensor` whose shape is broadcastable to `values`.\n",
    "      values: `Tensor` of any shape.\n",
    "    Returns:\n",
    "      `weights` broadcast to `values` shape.\n",
    "    \"\"\"\n",
    "    weights_shape = weights.get_shape()\n",
    "    values_shape = values.get_shape()\n",
    "    if(weights_shape.is_fully_defined() and\n",
    "       values_shape.is_fully_defined() and\n",
    "       weights_shape.is_compatible_with(values_shape)):\n",
    "        return weights\n",
    "    return math_ops.mul(\n",
    "        weights, array_ops.ones_like(values), name='broadcast_weights')\n",
    "\n",
    "\n",
    "# =========================================================================== #\n",
    "# TF Extended metrics: TP and FP arrays.\n",
    "# =========================================================================== #\n",
    "def precision_recall(num_gbboxes, num_detections, tp, fp, scores,\n",
    "                     dtype=tf.float64, scope=None):\n",
    "    \"\"\"Compute precision and recall from scores, true positives and false\n",
    "    positives booleans arrays\n",
    "    \"\"\"\n",
    "    # Input dictionaries: dict outputs as streaming metrics.\n",
    "    if isinstance(scores, dict):\n",
    "        d_precision = {}\n",
    "        d_recall = {}\n",
    "        for c in num_gbboxes.keys():\n",
    "            scope = 'precision_recall_%s' % c\n",
    "            p, r = precision_recall(num_gbboxes[c], num_detections[c],\n",
    "                                    tp[c], fp[c], scores[c],\n",
    "                                    dtype, scope)\n",
    "            d_precision[c] = p\n",
    "            d_recall[c] = r\n",
    "        return d_precision, d_recall\n",
    "\n",
    "    # Sort by score.\n",
    "    with tf.name_scope(scope, 'precision_recall',\n",
    "                       [num_gbboxes, num_detections, tp, fp, scores]):\n",
    "        # Sort detections by score.\n",
    "        scores, idxes = tf.nn.top_k(scores, k=num_detections, sorted=True)\n",
    "        tp = tf.gather(tp, idxes)\n",
    "        fp = tf.gather(fp, idxes)\n",
    "        # Computer recall and precision.\n",
    "        tp = tf.cumsum(tf.cast(tp, dtype), axis=0)\n",
    "        fp = tf.cumsum(tf.cast(fp, dtype), axis=0)\n",
    "        recall = _safe_div(tp, tf.cast(num_gbboxes, dtype), 'recall')\n",
    "        precision = _safe_div(tp, tp + fp, 'precision')\n",
    "        return tf.tuple([precision, recall])\n",
    "\n",
    "\n",
    "def streaming_tp_fp_arrays(num_gbboxes, tp, fp, scores,\n",
    "                           remove_zero_scores=True,\n",
    "                           metrics_collections=None,\n",
    "                           updates_collections=None,\n",
    "                           name=None):\n",
    "    \"\"\"Streaming computation of True and False Positive arrays. This metrics\n",
    "    also keeps track of scores and number of grountruth objects.\n",
    "    \"\"\"\n",
    "    # Input dictionaries: dict outputs as streaming metrics.\n",
    "    if isinstance(scores, dict) or isinstance(fp, dict):\n",
    "        d_values = {}\n",
    "        d_update_ops = {}\n",
    "        for c in num_gbboxes.keys():\n",
    "            scope = 'streaming_tp_fp_%s' % c\n",
    "            v, up = streaming_tp_fp_arrays(num_gbboxes[c], tp[c], fp[c], scores[c],\n",
    "                                           remove_zero_scores,\n",
    "                                           metrics_collections,\n",
    "                                           updates_collections,\n",
    "                                           name=scope)\n",
    "            d_values[c] = v\n",
    "            d_update_ops[c] = up\n",
    "        return d_values, d_update_ops\n",
    "\n",
    "    # Input Tensors...\n",
    "    with variable_scope.variable_scope(name, 'streaming_tp_fp',\n",
    "                                       [num_gbboxes, tp, fp, scores]):\n",
    "        num_gbboxes = math_ops.to_int64(num_gbboxes)\n",
    "        scores = math_ops.to_float(scores)\n",
    "        stype = tf.bool\n",
    "        tp = tf.cast(tp, stype)\n",
    "        fp = tf.cast(fp, stype)\n",
    "        # Reshape TP and FP tensors and clean away 0 class values.\n",
    "        scores = tf.reshape(scores, [-1])\n",
    "        tp = tf.reshape(tp, [-1])\n",
    "        fp = tf.reshape(fp, [-1])\n",
    "        # Remove TP and FP both false.\n",
    "        mask = tf.logical_or(tp, fp)\n",
    "        if remove_zero_scores:\n",
    "            rm_threshold = 1e-4\n",
    "            mask = tf.logical_and(mask, tf.greater(scores, rm_threshold))\n",
    "            scores = tf.boolean_mask(scores, mask)\n",
    "            tp = tf.boolean_mask(tp, mask)\n",
    "            fp = tf.boolean_mask(fp, mask)\n",
    "\n",
    "        # Local variables accumlating information over batches.\n",
    "        v_nobjects = _create_local('v_num_gbboxes', shape=[], dtype=tf.int64)\n",
    "        v_ndetections = _create_local('v_num_detections', shape=[], dtype=tf.int32)\n",
    "        v_scores = _create_local('v_scores', shape=[0, ])\n",
    "        v_tp = _create_local('v_tp', shape=[0, ], dtype=stype)\n",
    "        v_fp = _create_local('v_fp', shape=[0, ], dtype=stype)\n",
    "\n",
    "        # Update operations.\n",
    "        nobjects_op = state_ops.assign_add(v_nobjects,\n",
    "                                           tf.reduce_sum(num_gbboxes))\n",
    "        ndetections_op = state_ops.assign_add(v_ndetections,\n",
    "                                              tf.size(scores, out_type=tf.int32))\n",
    "        scores_op = state_ops.assign(v_scores, tf.concat([v_scores, scores], axis=0),\n",
    "                                     validate_shape=False)\n",
    "        tp_op = state_ops.assign(v_tp, tf.concat([v_tp, tp], axis=0),\n",
    "                                 validate_shape=False)\n",
    "        fp_op = state_ops.assign(v_fp, tf.concat([v_fp, fp], axis=0),\n",
    "                                 validate_shape=False)\n",
    "\n",
    "        # Value and update ops.\n",
    "        val = (v_nobjects, v_ndetections, v_tp, v_fp, v_scores)\n",
    "        with ops.control_dependencies([nobjects_op, ndetections_op,\n",
    "                                       scores_op, tp_op, fp_op]):\n",
    "            update_op = (nobjects_op, ndetections_op, tp_op, fp_op, scores_op)\n",
    "\n",
    "        if metrics_collections:\n",
    "            ops.add_to_collections(metrics_collections, val)\n",
    "        if updates_collections:\n",
    "            ops.add_to_collections(updates_collections, update_op)\n",
    "        return val, update_op\n",
    "\n",
    "\n",
    "# =========================================================================== #\n",
    "# Average precision computations.\n",
    "# =========================================================================== #\n",
    "def average_precision_voc12(precision, recall, name=None):\n",
    "    \"\"\"Compute (interpolated) average precision from precision and recall Tensors.\n",
    "\n",
    "    The implementation follows Pascal 2012 and ILSVRC guidelines.\n",
    "    See also: https://sanchom.wordpress.com/tag/average-precision/\n",
    "    \"\"\"\n",
    "    with tf.name_scope(name, 'average_precision_voc12', [precision, recall]):\n",
    "        # Convert to float64 to decrease error on Riemann sums.\n",
    "        precision = tf.cast(precision, dtype=tf.float64)\n",
    "        recall = tf.cast(recall, dtype=tf.float64)\n",
    "\n",
    "        # Add bounds values to precision and recall.\n",
    "        precision = tf.concat([[0.], precision, [0.]], axis=0)\n",
    "        recall = tf.concat([[0.], recall, [1.]], axis=0)\n",
    "        # Ensures precision is increasing in reverse order.\n",
    "        precision = tfe_math.cummax(precision, reverse=True)\n",
    "\n",
    "        # Riemann sums for estimating the integral.\n",
    "        # mean_pre = (precision[1:] + precision[:-1]) / 2.\n",
    "        mean_pre = precision[1:]\n",
    "        diff_rec = recall[1:] - recall[:-1]\n",
    "        ap = tf.reduce_sum(mean_pre * diff_rec)\n",
    "        return ap\n",
    "\n",
    "\n",
    "def average_precision_voc07(precision, recall, name=None):\n",
    "    \"\"\"Compute (interpolated) average precision from precision and recall Tensors.\n",
    "\n",
    "    The implementation follows Pascal 2007 guidelines.\n",
    "    See also: https://sanchom.wordpress.com/tag/average-precision/\n",
    "    \"\"\"\n",
    "    with tf.name_scope(name, 'average_precision_voc07', [precision, recall]):\n",
    "        # Convert to float64 to decrease error on cumulated sums.\n",
    "        precision = tf.cast(precision, dtype=tf.float64)\n",
    "        recall = tf.cast(recall, dtype=tf.float64)\n",
    "        # Add zero-limit value to avoid any boundary problem...\n",
    "        precision = tf.concat([precision, [0.]], axis=0)\n",
    "        recall = tf.concat([recall, [np.inf]], axis=0)\n",
    "\n",
    "        # Split the integral into 10 bins.\n",
    "        l_aps = []\n",
    "        for t in np.arange(0., 1.1, 0.1):\n",
    "            mask = tf.greater_equal(recall, t)\n",
    "            v = tf.reduce_max(tf.boolean_mask(precision, mask))\n",
    "            l_aps.append(v / 11.)\n",
    "        ap = tf.add_n(l_aps)\n",
    "        return ap\n",
    "\n",
    "\n",
    "def precision_recall_values(xvals, precision, recall, name=None):\n",
    "    \"\"\"Compute values on the precision/recall curve.\n",
    "\n",
    "    Args:\n",
    "      x: Python list of floats;\n",
    "      precision: 1D Tensor decreasing.\n",
    "      recall: 1D Tensor increasing.\n",
    "    Return:\n",
    "      list of precision values.\n",
    "    \"\"\"\n",
    "    with ops.name_scope(name, \"precision_recall_values\",\n",
    "                        [precision, recall]) as name:\n",
    "        # Add bounds values to precision and recall.\n",
    "        precision = tf.concat([[0.], precision, [0.]], axis=0)\n",
    "        recall = tf.concat([[0.], recall, [1.]], axis=0)\n",
    "        precision = tfe_math.cummax(precision, reverse=True)\n",
    "\n",
    "        prec_values = []\n",
    "        for x in xvals:\n",
    "            mask = tf.less_equal(recall, x)\n",
    "            val = tf.reduce_min(tf.boolean_mask(precision, mask))\n",
    "            prec_values.append(val)\n",
    "        return tf.tuple(prec_values)\n",
    "\n",
    "\n",
    "# =========================================================================== #\n",
    "# TF Extended metrics: old stuff!\n",
    "# =========================================================================== #\n",
    "def _precision_recall(n_gbboxes, n_detections, scores, tp, fp, scope=None):\n",
    "    \"\"\"Compute precision and recall from scores, true positives and false\n",
    "    positives booleans arrays\n",
    "    \"\"\"\n",
    "    # Sort by score.\n",
    "    with tf.name_scope(scope, 'prec_rec', [n_gbboxes, scores, tp, fp]):\n",
    "        # Sort detections by score.\n",
    "        scores, idxes = tf.nn.top_k(scores, k=n_detections, sorted=True)\n",
    "        tp = tf.gather(tp, idxes)\n",
    "        fp = tf.gather(fp, idxes)\n",
    "        # Computer recall and precision.\n",
    "        dtype = tf.float64\n",
    "        tp = tf.cumsum(tf.cast(tp, dtype), axis=0)\n",
    "        fp = tf.cumsum(tf.cast(fp, dtype), axis=0)\n",
    "        recall = _safe_div(tp, tf.cast(n_gbboxes, dtype), 'recall')\n",
    "        precision = _safe_div(tp, tp + fp, 'precision')\n",
    "\n",
    "        return tf.tuple([precision, recall])\n",
    "\n",
    "\n",
    "def streaming_precision_recall_arrays(n_gbboxes, rclasses, rscores,\n",
    "                                      tp_tensor, fp_tensor,\n",
    "                                      remove_zero_labels=True,\n",
    "                                      metrics_collections=None,\n",
    "                                      updates_collections=None,\n",
    "                                      name=None):\n",
    "    \"\"\"Streaming computation of precision / recall arrays. This metrics\n",
    "    keeps tracks of boolean True positives and False positives arrays.\n",
    "    \"\"\"\n",
    "    with variable_scope.variable_scope(name, 'stream_precision_recall',\n",
    "                                       [n_gbboxes, rclasses, tp_tensor, fp_tensor]):\n",
    "        n_gbboxes = math_ops.to_int64(n_gbboxes)\n",
    "        rclasses = math_ops.to_int64(rclasses)\n",
    "        rscores = math_ops.to_float(rscores)\n",
    "\n",
    "        stype = tf.int32\n",
    "        tp_tensor = tf.cast(tp_tensor, stype)\n",
    "        fp_tensor = tf.cast(fp_tensor, stype)\n",
    "\n",
    "        # Reshape TP and FP tensors and clean away 0 class values.\n",
    "        rclasses = tf.reshape(rclasses, [-1])\n",
    "        rscores = tf.reshape(rscores, [-1])\n",
    "        tp_tensor = tf.reshape(tp_tensor, [-1])\n",
    "        fp_tensor = tf.reshape(fp_tensor, [-1])\n",
    "        if remove_zero_labels:\n",
    "            mask = tf.greater(rclasses, 0)\n",
    "            rclasses = tf.boolean_mask(rclasses, mask)\n",
    "            rscores = tf.boolean_mask(rscores, mask)\n",
    "            tp_tensor = tf.boolean_mask(tp_tensor, mask)\n",
    "            fp_tensor = tf.boolean_mask(fp_tensor, mask)\n",
    "\n",
    "        # Local variables accumlating information over batches.\n",
    "        v_nobjects = _create_local('v_nobjects', shape=[], dtype=tf.int64)\n",
    "        v_ndetections = _create_local('v_ndetections', shape=[], dtype=tf.int32)\n",
    "        v_scores = _create_local('v_scores', shape=[0, ])\n",
    "        v_tp = _create_local('v_tp', shape=[0, ], dtype=stype)\n",
    "        v_fp = _create_local('v_fp', shape=[0, ], dtype=stype)\n",
    "\n",
    "        # Update operations.\n",
    "        nobjects_op = state_ops.assign_add(v_nobjects,\n",
    "                                           tf.reduce_sum(n_gbboxes))\n",
    "        ndetections_op = state_ops.assign_add(v_ndetections,\n",
    "                                              tf.size(rscores, out_type=tf.int32))\n",
    "        scores_op = state_ops.assign(v_scores, tf.concat([v_scores, rscores], axis=0),\n",
    "                                     validate_shape=False)\n",
    "        tp_op = state_ops.assign(v_tp, tf.concat([v_tp, tp_tensor], axis=0),\n",
    "                                 validate_shape=False)\n",
    "        fp_op = state_ops.assign(v_fp, tf.concat([v_fp, fp_tensor], axis=0),\n",
    "                                 validate_shape=False)\n",
    "\n",
    "        # Precision and recall computations.\n",
    "        # r = _precision_recall(nobjects_op, scores_op, tp_op, fp_op, 'value')\n",
    "        r = _precision_recall(v_nobjects, v_ndetections, v_scores,\n",
    "                              v_tp, v_fp, 'value')\n",
    "\n",
    "        with ops.control_dependencies([nobjects_op, ndetections_op,\n",
    "                                       scores_op, tp_op, fp_op]):\n",
    "            update_op = _precision_recall(nobjects_op, ndetections_op,\n",
    "                                          scores_op, tp_op, fp_op, 'update_op')\n",
    "\n",
    "            # update_op = tf.Print(update_op,\n",
    "            #                      [tf.reduce_sum(tf.cast(mask, tf.int64)),\n",
    "            #                       tf.reduce_sum(tf.cast(mask2, tf.int64)),\n",
    "            #                       tf.reduce_min(rscores),\n",
    "            #                       tf.reduce_sum(n_gbboxes)],\n",
    "            #                      'Metric: ')\n",
    "            # Some debugging stuff!\n",
    "            # update_op = tf.Print(update_op,\n",
    "            #                      [tf.shape(tp_op),\n",
    "            #                       tf.reduce_sum(tf.cast(tp_op, tf.int64), axis=0)],\n",
    "            #                      'TP and FP shape: ')\n",
    "            # update_op[0] = tf.Print(update_op,\n",
    "            #                      [nobjects_op],\n",
    "            #                      '# Groundtruth bboxes: ')\n",
    "            # update_op = tf.Print(update_op,\n",
    "            #                      [update_op[0][0],\n",
    "            #                       update_op[0][-1],\n",
    "            #                       tf.reduce_min(update_op[0]),\n",
    "            #                       tf.reduce_max(update_op[0]),\n",
    "            #                       tf.reduce_min(update_op[1]),\n",
    "            #                       tf.reduce_max(update_op[1])],\n",
    "            #                      'Precision and recall :')\n",
    "\n",
    "        if metrics_collections:\n",
    "            ops.add_to_collections(metrics_collections, r)\n",
    "        if updates_collections:\n",
    "            ops.add_to_collections(updates_collections, update_op)\n",
    "        return r, update_op\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
