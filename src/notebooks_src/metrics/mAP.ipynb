{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ../../notebooks_src/losses/util.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/box_encode_decode/configs.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/models/configs.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/config_util.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/load_data/configs.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/box_encode_decode/ssd/encode.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/box_encode_decode/ssd/make_anchors_orig.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/load_data/get_generator.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/load_data/generator/generator.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/box_encode_decode/util.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/load_data/generator/batch_fetcher.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/box_encode_decode/ssd/decode.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/postprocessing/ssd.ipynb\n",
      "['', '/usr/lib/python2.7', '/usr/lib/python2.7/plat-x86_64-linux-gnu', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/home/evan/.local/lib/python2.7/site-packages', '/usr/local/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages/PILcompat', '/usr/lib/python2.7/dist-packages/gtk-2.0', '/usr/local/lib/python2.7/dist-packages/IPython/extensions', '/home/evan/.ipython', '../../']\n",
      "importing Jupyter notebook from ../../notebooks_src/tf_extended/math.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/tf_extended/tensors.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/postprocessing/bboxes.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/postprocessing/utils.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/metrics/util.ipynb\n",
      "box_encode_decode_configs\n",
      "importing Jupyter notebook from ../../notebooks_src/configs/box_encode_decode_configs.ipynb\n",
      "callbacks_configs\n",
      "importing Jupyter notebook from ../../notebooks_src/configs/callbacks_configs.ipynb\n",
      "fit_configs\n",
      "importing Jupyter notebook from ../../notebooks_src/configs/fit_configs.ipynb\n",
      "labels_configs\n",
      "importing Jupyter notebook from ../../notebooks_src/configs/labels_configs.ipynb\n",
      "load_data_configs\n",
      "importing Jupyter notebook from ../../notebooks_src/configs/load_data_configs.ipynb\n",
      "losses_configs\n",
      "importing Jupyter notebook from ../../notebooks_src/configs/losses_configs.ipynb\n",
      "metrics_configs\n",
      "importing Jupyter notebook from ../../notebooks_src/configs/metrics_configs.ipynb\n",
      "models_configs\n",
      "importing Jupyter notebook from ../../notebooks_src/configs/models_configs.ipynb\n",
      "optimizers_configs\n",
      "importing Jupyter notebook from ../../notebooks_src/configs/optimizers_configs.ipynb\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from nbfinder import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "if __name__ == \"__main__\":\n",
    "    sys.path.append(\"../../\")\n",
    "from notebooks_src.losses.util import unpack_net_output, sort_some_lists_of_tensors\n",
    "from notebooks_src.box_encode_decode.ssd.encode import encode, get_boxes_labels_zero_out_holes\n",
    "from notebooks_src.box_encode_decode.ssd.decode import decode\n",
    "from notebooks_src.postprocessing.ssd import detected_bboxes\n",
    "from notebooks_src.postprocessing.bboxes import bboxes_matching_batch\n",
    "from notebooks_src.postprocessing.utils import reshape_list\n",
    "from notebooks_src.metrics.util import streaming_tp_fp_arrays, precision_recall, average_precision_voc07, average_precision_voc12\n",
    "from notebooks_src.configs import configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_batch_metrics(y_true, y_preds):\n",
    "    gclasses, glocalizations, gscores = encode(y_true)\n",
    "\n",
    "    \n",
    "    # changes so labels go from 1 to 4\n",
    "    glabels, gbboxes = get_boxes_labels_zero_out_holes(y_true)\n",
    "    localizations, logits, predictions = unpack_net_output(y_preds)\n",
    "    \n",
    "    logits, localizations, gclasses, glocalizations, gscores, predictions = sort_some_lists_of_tensors(logits,\n",
    "                                                                                           localizations, \n",
    "                                                                                           gclasses, \n",
    "                                                                                           glocalizations, \n",
    "                                                                                          gscores, predictions)\n",
    "\n",
    "    #boolean mask of whether gtruth object is difficult or not (only used for pascal voc?)\n",
    "    gdifficults = tf.zeros_like(glabels)\n",
    "\n",
    "    \n",
    "    # Performing post-processing on CPU: loop-intensive, usually more efficient.\n",
    "    #with tf.device('/device:CPU:0'):\n",
    "    localizations = decode(localizations)\n",
    "    \n",
    "    # get top k  predicted boxes after nms\n",
    "    rscores, rbboxes = detected_bboxes(predictions, localizations,\n",
    "                            select_threshold=configs[\"select_threshold\"],\n",
    "                            nms_threshold=configs[\"nms_threshold\"],\n",
    "                            clipping_bbox=None,\n",
    "                            top_k=configs[\"select_top_k\"],\n",
    "                            keep_top_k=configs[\"keep_top_k\"])\n",
    "    \n",
    "    #match the predicted boxes to ground truth boxes and compute the TP and FP statistics.\n",
    "    num_gbboxes, tp, fp, rscores = \\\n",
    "    bboxes_matching_batch(rscores.keys(), rscores, rbboxes,\n",
    "                              glabels, gbboxes, gdifficults,\n",
    "                              matching_threshold=configs[\"matching_threshold\"])\n",
    "    \n",
    "    return num_gbboxes, tp, fp, rscores    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EpochMetrics(object):\n",
    "    def __init__(self):\n",
    "        self.num_gbboxes = {}\n",
    "        self.tp = {}\n",
    "        self.fp = {}\n",
    "        self.rscores = {}\n",
    "    def update_metrics(self,num_gbboxes, tp, fp, rscores):\n",
    "        self.num_gbboxes = self.increment_dict(self.num_gbboxes, num_gbboxes)\n",
    "        self.tp = self.extend_to_dict(self.tp, tp)\n",
    "        self.fp = self.extend_to_dict(self.fp, fp)\n",
    "        self.rscores = self.extend_to_dict(self.rscores, rscores)\n",
    "\n",
    "\n",
    "    def extend_to_dict(self,main_dict,extending_dict):\n",
    "        if len(main_dict.keys()) == 0:\n",
    "            main_dict.update({k:[] for k in extending_dict.keys()})\n",
    "        for k,v in extending_dict.iteritems():\n",
    "            k_list = [list(arr) for arr in extending_dict[k]]\n",
    "            for sublist in k_list:\n",
    "                main_dict[k].extend(sublist)\n",
    "        return main_dict\n",
    "    def increment_dict(self,main_dict, incrementing_dict):\n",
    "        if len(main_dict.keys()) == 0:\n",
    "            main_dict.update(incrementing_dict)\n",
    "            for k,v in main_dict.iteritems():\n",
    "                # for lists of num_classes for each batch\n",
    "                main_dict[k] = sum(v)\n",
    "        else:\n",
    "            for k,v in incrementing_dict.iteritems():\n",
    "                main_dict[k] += sum(v)\n",
    "        return main_dict\n",
    "    def get_final_metrics(self):\n",
    "        num_detections = {c:len(v) for c,v in self.rscores.iteritems()}\n",
    "        return self.num_gbboxes,  num_detections, self.tp, self.fp, self.rscores\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_ap_one_class():\n",
    "    num_classes = configs[\"num_classes\"]\n",
    "    \n",
    "    \n",
    "    num_gbboxes = tf.placeholder(dtype=tf.int32)\n",
    "    tp = tf.placeholder(dtype=tf.bool)\n",
    "    fp = tf.placeholder(dtype=tf.bool)\n",
    "    rscores = tf.placeholder(dtype=tf.float32)\n",
    "    num_detections = tf.placeholder(dtype=tf.int32)\n",
    "    \n",
    "    \n",
    "    # Add to summaries precision/recall values.\n",
    "    aps_voc07 = {}\n",
    "    aps_voc12 = {}\n",
    "\n",
    "    # Precison and recall values.\n",
    "    prec, rec = precision_recall(num_gbboxes, num_detections,\n",
    "                                tp, fp, rscores )\n",
    "\n",
    "    # Average precision VOC07.\n",
    "    v = average_precision_voc07(prec, rec)\n",
    "    aps_voc07 = v\n",
    "\n",
    "    # Average precision VOC12.\n",
    "    v = average_precision_voc12(prec, rec)\n",
    "\n",
    "    aps_voc12 = v\n",
    "        \n",
    "    return aps_voc12,[num_gbboxes, num_detections, tp, fp, rscores]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'box' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b7cc9b63ec41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mepm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEpochMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#         for ind, (im, box) in enumerate(gen):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mupdated_batch_metrics\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mepm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mupdated_batch_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'box' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    with tf.Session() as sess:\n",
    "        #from notebooks_src.load_data.get_generator import get_generator\n",
    "        #gen=get_generator(\"tr\", batch_size=2)\n",
    "        y_true = tf.placeholder(tf.float32,shape=(2,15,5),name=\"y_true\")\n",
    "        shapes = [(2, 6, 9, 48),\n",
    "                 (2, 3, 5, 32),\n",
    "                 (2, 96, 144, 32),\n",
    "                 (2, 24, 36, 48),\n",
    "                 (2, 12, 18, 48),\n",
    "                 (2, 48, 72, 48),\n",
    "                 (2, 1, 1, 32)]\n",
    "\n",
    "        y_preds = [tf.ones((shape)) for shape in shapes]\n",
    "        #num_gbboxes, tp, fp, rscores \n",
    "        batch_metrics = calc_batch_metrics(y_true, y_preds)\n",
    "        epm = EpochMetrics()\n",
    "#         for ind, (im, box) in enumerate(gen):\n",
    "        updated_batch_metrics  = sess.run(batch_metrics, feed_dict={y_true:box})\n",
    "        epm.update_metrics(*updated_batch_metrics)\n",
    "        \n",
    "        final_metrics = epm.get_final_metrics()\n",
    "        aps_voc12, placeholders = calc_ap_one_class()\n",
    "        all_aps12 = {}\n",
    "\n",
    "        print final_metrics\n",
    "        for c in fnum_gbboxes.keys():\n",
    "            placefillers = [d[c] for d in final_metrics]\n",
    "            all_aps12[c] = sess.run(aps_voc12, feed_dict = dict(zip(placeholders, placefillers)) )\n",
    "        print all_aps12\n",
    "        \n",
    "        mAP12 = np.mean(all_aps12.values())\n",
    "        print mAP12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
