{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from nbfinder import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "import tensorflow as tf\n",
    "if __name__ == \"__main__\":\n",
    "    sys.path.append(\"../../\")\n",
    "from notebooks_src.losses.util import unpack_net_output, sort_some_lists_of_tensors\n",
    "from notebooks_src.box_encode_decode.ssd.encode import encode\n",
    "from notebooks_src.box_encode_decode.ssd.decode import decode\n",
    "from notebooks_src.metrics.configs import configs\n",
    "from notebooks_src.load_data.configs import configs as data_configs\n",
    "from notebooks_src.postprocessing.ssd import detected_bboxes\n",
    "configs.update(data_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_accuracy(y_true, y_preds):\n",
    "    gclasses, glocalizations, gscores = encode(y_true)\n",
    "\n",
    "\n",
    "    localizations, logits, predictions = unpack_net_output(y_preds)\n",
    "    \n",
    "    logits, localizations, gclasses, glocalizations, gscores, predictions = sort_some_lists_of_tensors(logits,\n",
    "                                                                                           localizations, \n",
    "                                                                                           gclasses, \n",
    "                                                                                           glocalizations, \n",
    "                                                                                           gscores, predictions)\n",
    "\n",
    "    localizations = decode(localizations)\n",
    "    \n",
    "    # get top k  predicted boxes after nms\n",
    "    rscores, rbboxes = detected_bboxes(predictions, localizations,\n",
    "                            select_threshold=configs[\"select_threshold\"],\n",
    "                            nms_threshold=configs[\"nms_threshold\"],\n",
    "                            clipping_bbox=None,\n",
    "                            top_k=configs[\"select_top_k\"],\n",
    "                            keep_top_k=configs[\"keep_top_k\"])\n",
    "    return rscores, rboxes\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "detected_bboxes() takes at least 3 arguments (7 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-10d475b5acb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m#         for im, box in gen:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#             print sess.run(final_loss, feed_dict={bboxes:box})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-8b4f43fc2ed3>\u001b[0m in \u001b[0;36mcalc_accuracy\u001b[0;34m(y_true, y_preds)\u001b[0m\n\u001b[1;32m     19\u001b[0m                             \u001b[0mclipping_bbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                             \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"select_top_k\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                             keep_top_k=configs[\"keep_top_k\"])\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrboxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: detected_bboxes() takes at least 3 arguments (7 given)"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    with tf.Session() as sess:\n",
    "        from notebooks_src.load_data.get_generator import get_generator\n",
    "\n",
    "        gen=get_generator(\"tr\", batch_size=2)\n",
    "        y_true = tf.placeholder(tf.float32,shape=(2,15,5),name=\"y_true\")\n",
    "        shapes = [(2, 6, 9, 48),\n",
    "                 (2, 3, 5, 32),\n",
    "                 (2, 96, 144, 32),\n",
    "                 (2, 24, 36, 48),\n",
    "                 (2, 12, 18, 48),\n",
    "                 (2, 48, 72, 48),\n",
    "                 (2, 1, 1, 32)]\n",
    "\n",
    "        y_preds = [tf.ones((shape)) for shape in shapes]\n",
    "        rs,rb = calc_accuracy(y_true, y_preds)\n",
    "#         for im, box in gen:\n",
    "#             print sess.run(final_loss, feed_dict={bboxes:box})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'ssd_bboxes_decode/stack:0' shape=(2, 96, 144, 4, 4) dtype=float32>,\n",
       " <tf.Tensor 'ssd_bboxes_decode/stack_1:0' shape=(2, 48, 72, 6, 4) dtype=float32>,\n",
       " <tf.Tensor 'ssd_bboxes_decode/stack_2:0' shape=(2, 24, 36, 6, 4) dtype=float32>,\n",
       " <tf.Tensor 'ssd_bboxes_decode/stack_3:0' shape=(2, 12, 18, 6, 4) dtype=float32>,\n",
       " <tf.Tensor 'ssd_bboxes_decode/stack_4:0' shape=(2, 6, 9, 6, 4) dtype=float32>,\n",
       " <tf.Tensor 'ssd_bboxes_decode/stack_5:0' shape=(2, 3, 5, 4, 4) dtype=float32>,\n",
       " <tf.Tensor 'ssd_bboxes_decode/stack_6:0' shape=(2, 1, 1, 4, 4) dtype=float32>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "localizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "batch_shape = [1] * 5 + [len(ssd_anchors)] * 3\n",
    "\n",
    "\n",
    "# Make a batch of data\n",
    "r = tf.train.batch(\n",
    "    tf_utils.reshape_list([image, glabels, gbboxes, gdifficults, gbbox_img,\n",
    "                           gclasses, glocalisations, gscores]),\n",
    "    batch_size=FLAGS.batch_size,\n",
    "    num_threads=FLAGS.num_preprocessing_threads,\n",
    "    capacity=5 * FLAGS.batch_size,\n",
    "    dynamic_pad=True)\n",
    "(b_image, b_glabels, b_gbboxes, b_gdifficults, b_gbbox_img, b_gclasses,\n",
    " b_glocalisations, b_gscores) = tf_utils.reshape_list(r, batch_shape)\n",
    "\n",
    "# =================================================================== #\n",
    "# SSD Network + Ouputs decoding.\n",
    "# =================================================================== #\n",
    "dict_metrics = {}\n",
    "arg_scope = ssd_net.arg_scope(data_format=DATA_FORMAT)\n",
    "# 1. get outputs from network\n",
    "# localisations is the box corrdinates\n",
    "# logits is the raw output of the convolution for classes (ie unnormalized prob dist)\n",
    "# predictions is the softmax of the logits\n",
    "predictions, localisations, logits, end_points = \\\n",
    "    ssd_net.net(b_image, is_training=False)\n",
    "\n",
    "\n",
    "# Performing post-processing on CPU: loop-intensive, usually more efficient.\n",
    "with tf.device('/device:CPU:0'):\n",
    "    \n",
    "    \n",
    "# decode encoded output for normalization to box coords?\n",
    "localisations = ssd_net.bboxes_decode(localisations, ssd_anchors)\n",
    "\n",
    "\n",
    "# get top k  predicted boxes after nms\n",
    "rscores, rbboxes = \\\n",
    "    ssd_net.detected_bboxes(predictions, localisations,\n",
    "                            select_threshold=FLAGS.select_threshold,\n",
    "                            nms_threshold=FLAGS.nms_threshold,\n",
    "                            clipping_bbox=None,\n",
    "                            top_k=FLAGS.select_top_k,\n",
    "                            keep_top_k=FLAGS.keep_top_k)\n",
    "    \n",
    "    \n",
    "#match the predicted boxes to ground truth boxes and compute the TP and FP statistics.\n",
    "num_gbboxes, tp, fp, rscores = \\\n",
    "    tfe.bboxes_matching_batch(rscores.keys(), rscores, rbboxes,\n",
    "                              b_glabels, b_gbboxes, b_gdifficults,\n",
    "                              matching_threshold=FLAGS.matching_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tp_fp_metric = tfe.streaming_tp_fp_arrays(num_gbboxes, tp, fp, rscores)\n",
    "            for c in tp_fp_metric[0].keys():\n",
    "                dict_metrics['tp_fp_%s' % c] = (tp_fp_metric[0][c],\n",
    "                                                tp_fp_metric[1][c])\n",
    "\n",
    "            # Add to summaries precision/recall values.\n",
    "            aps_voc07 = {}\n",
    "            aps_voc12 = {}\n",
    "            for c in tp_fp_metric[0].keys():\n",
    "                # Precison and recall values.\n",
    "                prec, rec = tfe.precision_recall(*tp_fp_metric[0][c])\n",
    "\n",
    "                # Average precision VOC07.\n",
    "                v = tfe.average_precision_voc07(prec, rec)\n",
    "                summary_name = 'AP_VOC07/%s' % c\n",
    "                op = tf.summary.scalar(summary_name, v, collections=[])\n",
    "                # op = tf.Print(op, [v], summary_name)\n",
    "                tf.add_to_collection(tf.GraphKeys.SUMMARIES, op)\n",
    "                aps_voc07[c] = v\n",
    "\n",
    "                # Average precision VOC12.\n",
    "                v = tfe.average_precision_voc12(prec, rec)\n",
    "                summary_name = 'AP_VOC12/%s' % c\n",
    "                op = tf.summary.scalar(summary_name, v, collections=[])\n",
    "                # op = tf.Print(op, [v], summary_name)\n",
    "                tf.add_to_collection(tf.GraphKeys.SUMMARIES, op)\n",
    "                aps_voc12[c] = v\n",
    "\n",
    "            # Mean average precision VOC07.\n",
    "            summary_name = 'AP_VOC07/mAP'\n",
    "            mAP = tf.add_n(list(aps_voc07.values())) / len(aps_voc07)\n",
    "            op = tf.summary.scalar(summary_name, mAP, collections=[])\n",
    "            op = tf.Print(op, [mAP], summary_name)\n",
    "            tf.add_to_collection(tf.GraphKeys.SUMMARIES, op)\n",
    "\n",
    "            # Mean average precision VOC12.\n",
    "            summary_name = 'AP_VOC12/mAP'\n",
    "            mAP = tf.add_n(list(aps_voc12.values())) / len(aps_voc12)\n",
    "            op = tf.summary.scalar(summary_name, mAP, collections=[])\n",
    "            op = tf.Print(op, [mAP], summary_name)\n",
    "            tf.add_to_collection(tf.GraphKeys.SUMMARIES, op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class streaming_acc_class(object):\n",
    "    def __init__(self, inp mode=\"VOC\"):\n",
    "        #intialize tensors for calculating one batch of acc\n",
    "        pass\n",
    "        \n",
    "    def update_acc(self,x,y):\n",
    "        #do a forward pass with feed dict and get tp/fp for each class and append to the master ones\n",
    "        pass\n",
    "    def get_final_acc(self):\n",
    "        # do final prec_recall on each class and return the average as well\n",
    "        \n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
