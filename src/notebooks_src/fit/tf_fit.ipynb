{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ../../notebooks_src/metrics/mAP.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/postprocessing/utils.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/box_encode_decode/ssd/encode.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/box_encode_decode/ssd/make_anchors_orig.ipynb\n",
      "box_encode_decode_configs\n",
      "importing Jupyter notebook from ../../notebooks_src/configs/box_encode_decode_configs.ipynb\n",
      "callbacks_configs\n",
      "importing Jupyter notebook from ../../notebooks_src/configs/callbacks_configs.ipynb\n",
      "fit_configs\n",
      "importing Jupyter notebook from ../../notebooks_src/configs/fit_configs.ipynb\n",
      "labels_configs\n",
      "importing Jupyter notebook from ../../notebooks_src/configs/labels_configs.ipynb\n",
      "load_data_configs\n",
      "importing Jupyter notebook from ../../notebooks_src/configs/load_data_configs.ipynb\n",
      "losses_configs\n",
      "importing Jupyter notebook from ../../notebooks_src/configs/losses_configs.ipynb\n",
      "metrics_configs\n",
      "importing Jupyter notebook from ../../notebooks_src/configs/metrics_configs.ipynb\n",
      "models_configs\n",
      "importing Jupyter notebook from ../../notebooks_src/configs/models_configs.ipynb\n",
      "optimizers_configs\n",
      "importing Jupyter notebook from ../../notebooks_src/configs/optimizers_configs.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/load_data/get_generator.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/load_data/generator/generator.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/box_encode_decode/util.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/load_data/generator/batch_fetcher.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/box_encode_decode/ssd/utils.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/box_encode_decode/ssd/decode.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/postprocessing/ssd.ipynb\n",
      "['', '/usr/lib/python2.7', '/usr/lib/python2.7/plat-x86_64-linux-gnu', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/home/evan/.local/lib/python2.7/site-packages', '/usr/local/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages/PILcompat', '/usr/lib/python2.7/dist-packages/gtk-2.0', '/usr/local/lib/python2.7/dist-packages/IPython/extensions', '/home/evan/.ipython', '../../']\n",
      "importing Jupyter notebook from ../../notebooks_src/tf_extended/math.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/tf_extended/tensors.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/postprocessing/bboxes.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/postprocessing/unpack.ipynb\n",
      "importing Jupyter notebook from ../../notebooks_src/metrics/utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from nbfinder import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "if __name__ == \"__main__\":\n",
    "    sys.path.append(\"../../\")\n",
    "from notebooks_src.metrics.mAP import calc_batch_metrics, EpochMetrics, calc_ap_one_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit(model, generator, val_generator,num_epochs, loss_func, opt):\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "\n",
    "        loss_tensor, label  = get_loss_tensor(loss_func, model, generator)\n",
    "        train_step = opt.minimize(loss_tensor)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        input_ = model.input\n",
    "        for ep in range(num_epochs):\n",
    "            losses = []\n",
    "     \n",
    "            steps_per_epoch= generator.num_ims / generator.batch_size\n",
    "\n",
    "            for step in range(steps_per_epoch):\n",
    "                im, boxes = generator.next()\n",
    "                _,cur_loss = sess.run([train_step, loss_tensor],feed_dict={input_:im,label:boxes})\n",
    "                losses.append(cur_loss)     \n",
    "                print \"loss: %8.4f\"% cur_loss\n",
    "            tr_loss = sum(losses) / len(losses)\n",
    "            #tr_loss = get_epoch_loss(generator, model, train_step, loss_tensor,sess,label)\n",
    "            #val_loss = get_val_epoch_loss(generator, model,loss_tensor,sess,label)\n",
    "            \n",
    "            val_mAP, val_APs = get_epoch_accuracy(val_generator, model, sess, input_)\n",
    "            tr_mAP, tr_APs = get_epoch_accuracy(generator, model, sess, input_)\n",
    "            \n",
    "            print \"tr_loss: \", tr_loss\n",
    "            #print \"val_loss: \", val_loss\n",
    "            print \"val_mAP: \", val_mAP\n",
    "            print \"tr_mAP: \", tr_mAP\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_val_epoch_loss(generator,model,loss_tensor,sess,label):\n",
    "    losses = []\n",
    "    input_ = model.input\n",
    "    steps_per_epoch= generator.num_ims / generator.batch_size\n",
    "\n",
    "    for step in range(steps_per_epoch):\n",
    "        im, boxes = generator.next()\n",
    "        cur_loss = sess.run(loss_tensor,feed_dict={input_:im,label:boxes})\n",
    "        losses.append(cur_loss)     \n",
    "        print \"loss: %8.4f\"% cur_loss\n",
    "    return sum(losses) / len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_epoch_loss(generator,model, train_step, loss_tensor,sess,label):\n",
    "    losses = []\n",
    "    input_ = model.input\n",
    "    steps_per_epoch= generator.num_ims / generator.batch_size\n",
    "\n",
    "    for step in range(steps_per_epoch):\n",
    "        im, boxes = generator.next()\n",
    "        _,cur_loss = sess.run([train_step, loss_tensor],feed_dict={input_:im,label:boxes})\n",
    "        losses.append(cur_loss)     \n",
    "        print \"loss: %8.4f\"% cur_loss\n",
    "    return sum(losses) / len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_epoch_accuracy(generator, model, sess,input_):\n",
    "    epm = EpochMetrics()\n",
    "    batch_accuracy_tensors, y_true = get_batch_accuracy_tensors(calc_batch_metrics, model, generator)\n",
    "    steps_per_epoch = generator.num_ims / generator.batch_size\n",
    "    for step in range(steps_per_epoch):\n",
    "        im, boxes = generator.next()\n",
    "        updated_metrics = sess.run(batch_accuracy_tensors, feed_dict={y_true:boxes, input_:im})\n",
    "        epm.update_metrics(*updated_metrics)\n",
    "\n",
    "    final_metrics = epm.get_final_metrics()\n",
    "    aps_voc12, placeholders= calc_ap_one_class()\n",
    "    all_aps12 = {}\n",
    "\n",
    "\n",
    "    for c in final_metrics[0].keys():\n",
    "        placefillers = [d[c] for d in final_metrics]\n",
    "        all_aps12[c] = sess.run(aps_voc12, feed_dict = dict(zip(placeholders, placefillers)) )\n",
    "\n",
    "\n",
    "    mAP = np.mean(all_aps12.values())\n",
    "    return mAP, all_aps12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_y_true_y_preds_tensors(model, batch_size, label_shape):\n",
    "    output_tensors = model.outputs\n",
    "        \n",
    "    label_batch_shape = tuple([batch_size] + list(label_shape))\n",
    "        \n",
    "        \n",
    "    label_tensor = tf.placeholder(tf.float32,shape=label_batch_shape, name=\"label\")\n",
    "    return label_tensor, output_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loss_tensor(loss_func, model, generator):\n",
    "        batch_size = generator.batch_size\n",
    "        \n",
    "        \n",
    "        y_true, y_preds = get_y_true_y_preds_tensors(model, batch_size,generator.data.labels.shape[1:])\n",
    "        loss_tensor = loss_func(y_true, y_preds)\n",
    "\n",
    "        return loss_tensor, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch_accuracy_tensors(acc_func, model,generator):\n",
    "        batch_size = generator.batch_size\n",
    "        y_true, y_preds = get_y_true_y_preds_tensors(model, batch_size,generator.data.labels.shape[1:])\n",
    "        batch_metrics = calc_batch_metrics(y_true, y_preds)\n",
    "        return batch_metrics, y_true\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
