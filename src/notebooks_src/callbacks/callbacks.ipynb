{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from configs.ipynb\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 2] No such file or directory: './logs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5535a75adbd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnbfinder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotebookFinder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNotebookFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mconfigs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/evan/hur-detect/src/notebooks_src/callbacks/nbfinder.pyc\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(self, fullname)\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_transformer_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;31m# run the code in themodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_user_ns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/evan/hur-detect/src/notebooks_src/callbacks/configs.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 2] No such file or directory: './logs'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from nbfinder import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "from configs import configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WeightPrinter(keras.callbacks.Callback):\n",
    "\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        weights = self.model.get_weights()\n",
    "        for i, weight_set in enumerate(weights):\n",
    "\n",
    "            weights_norm = np.sum(np.square(weight_set))\n",
    "            min_weight = np.min(weight_set)\n",
    "            max_weight = np.max(weight_set)\n",
    "            weight_shape = weight_set.shape\n",
    "            sys.stderr.write(\"\\n ####### \\n Weight Set %i shape: %s\\nweight norm: %5.2f \\nmin_weight: %5.2f\\nmax_weight: %5.2f\\n ##### \\n\"%(i, str(weight_shape),\n",
    "                                                                                                               weights_norm,\n",
    "                                                                                                               min_weight,\n",
    "                                                                                                               max_weight))\n",
    "        sys.stderr.write(str(logs.get(\"loss\")))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LearnCurve(keras.callbacks.Callback):\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.glob_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        #sys.stderr.write(str(logs))\n",
    "        self.losses.append(logs.get('loss'))\n",
    "    def on_epoch_end(self,epoch, logs):\n",
    "        self.glob_losses.append(logs.get('loss'))\n",
    "        if epoch % 1 ==0:\n",
    "\n",
    "            plt.plot(self.glob_losses)\n",
    "            plt.show()\n",
    "        \n",
    "        \n",
    "\n",
    "    def on_train_end(self,*args):\n",
    "        plt.plot(self.glob_losses)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sched(epoch_ind):\n",
    "    if epoch_ind < 50:\n",
    "        return 0.0001\n",
    "    elif epoch_ind < 100:\n",
    "        return 0.00001\n",
    "    else:\n",
    "        return 0.000001\n",
    "\n",
    "lr_sched_cback = keras.callbacks.LearningRateScheduler(schedule=sched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TensorBoardLearnCurve(keras.callbacks.Callback):\n",
    "    \"\"\"Tensorboard basic visualizations.\n",
    "    This callback writes a log for TensorBoard, which allows\n",
    "    you to visualize dynamic graphs of your training and test\n",
    "    metrics, as well as activation histograms for the different\n",
    "    layers in your model.\n",
    "    TensorBoard is a visualization tool provided with TensorFlow.\n",
    "    If you have installed TensorFlow with pip, you should be able\n",
    "    to launch TensorBoard from the command line:\n",
    "    ```\n",
    "    tensorboard --logdir=/full_path_to_your_logs\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, log_dir='./logs',\n",
    "                 histogram_freq=0,\n",
    "                 write_graph=False,\n",
    "                 write_images=False):\n",
    "        super(TensorBoardLearnCurve, self).__init__()\n",
    "        if K.backend() != 'tensorflow':\n",
    "            raise RuntimeError('TensorBoard callback only works '\n",
    "                               'with the TensorFlow backend.')\n",
    "        self.log_dir = log_dir\n",
    "\n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "        self.sess = K.get_session()\n",
    "        \n",
    "        self.writer = tf.summary.FileWriter(self.log_dir)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "\n",
    "        for name, value in logs.items():\n",
    "            sys.stderr.write(name + \"\\n\")\n",
    "            if name in ['batch', 'size']:\n",
    "                continue\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value.item()\n",
    "            summary_value.tag = name\n",
    "            self.writer.add_summary(summary, epoch)\n",
    "        self.writer.flush()\n",
    "\n",
    "    def on_train_end(self, _):\n",
    "        self.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=configs[\"min_delta\"], patience=configs[\"patience\"], verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TB = TensorBoardLearnCurve(log_dir='./logs/'+ configs[\"experiment_name\"],\n",
    "                                            histogram_freq=1, write_graph=False, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_callbacks():\n",
    "    return [LearnCurve(), TB, early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
