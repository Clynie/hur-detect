{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from make_anchors_orig.ipynb\n",
      "importing Jupyter notebook from ../../../notebooks_src/box_encode_decode/configs.ipynb\n",
      "importing Jupyter notebook from ../../../notebooks_src/losses/util.ipynb\n",
      "importing Jupyter notebook from ../../../notebooks_src/models/configs.ipynb\n",
      "importing Jupyter notebook from ../../../notebooks_src/config_util.ipynb\n",
      "importing Jupyter notebook from ../../../notebooks_src/load_data/configs.ipynb\n",
      "importing Jupyter notebook from ../../../notebooks_src/load_data/get_generator.ipynb\n",
      "importing Jupyter notebook from ../../../notebooks_src/load_data/generator/generator.ipynb\n",
      "importing Jupyter notebook from ../../../notebooks_src/box_encode_decode/util.ipynb\n",
      "importing Jupyter notebook from ../../../notebooks_src/load_data/generator/batch_fetcher.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Some of this code came from this license:\n",
    "# Copyright 2015 Paul Balanca. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "import sys\n",
    "from nbfinder import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "if __name__ == \"__main__\":\n",
    "    sys.path.append(\"../../../\")\n",
    "from make_anchors_orig import make_anchors,make_anchors_for_one_fmap\n",
    "import notebooks_src.tf_extended as tfe\n",
    "from notebooks_src.losses.util import convert_tf_shape_to_int_tuple\n",
    "from notebooks_src.load_data.get_generator import get_generator\n",
    "from notebooks_src.load_data.configs import configs as data_configs\n",
    "from notebooks_src.models.configs import configs as model_configs\n",
    "from notebooks_src.box_encode_decode.configs import configs as configs\n",
    "configs.update(data_configs)\n",
    "configs.update(model_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode(label, im_shape=configs[\"input_shape\"][-2:]):\n",
    "    \n",
    "    \"\"\"input: label (a Nx15x5 tensor, where N is batch_size)\n",
    "       output: batch_target_labels, batch_target_localizations, batch_target_scores\n",
    "                 * each of these is a list of tensors, one tensor for each fmap size,\n",
    "                 * 1st dim of tensor is batch size \"\"\"\n",
    "    \n",
    "    num_examples_per_batch = configs[\"batch_size\"]\n",
    "    \n",
    "    #make anchors\n",
    "    anchors = make_anchors(im_shape)\n",
    "    \n",
    "    batch_target_labels, batch_target_localizations, batch_target_scores = [], [], []\n",
    "    for example_ind in range(num_examples_per_batch):\n",
    "        #grab each box_coord thing\n",
    "        _, cur_label_tensor, _ = tf.split(label, num_or_size_splits=(example_ind, 1, num_examples_per_batch - example_ind -1 ))\n",
    "        cur_label_tensor = tf.squeeze(cur_label_tensor, axis=0)\n",
    "        classes, bboxes = encode_prep(cur_label_tensor)\n",
    "    \n",
    "        #encode boxes\n",
    "        target_labels_one_example, target_localizations_one_example, target_scores_one_example = bboxes_encode(classes, bboxes, anchors,scope=None)\n",
    "        \n",
    "        \n",
    "        batch_target_labels.append(target_labels_one_example)\n",
    "\n",
    "        batch_target_localizations.append(target_localizations_one_example)\n",
    "        batch_target_scores.append(target_scores_one_example)\n",
    "        \n",
    "    \n",
    "    #stack each label tensor of the same fmap size for each example\n",
    "    target_labels = [tf.stack(labels,axis=0) for labels in zip(*batch_target_labels)]\n",
    "    target_localizations = [tf.stack(localizations,axis=0) for localizations in zip(*batch_target_localizations)] \n",
    "    target_scores = [tf.stack(scores,axis=0) for scores in zip(*batch_target_scores)] \n",
    "    \n",
    "    return target_labels, target_localizations, target_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_prep(label_tensor):\n",
    "    \"\"\"takes:\n",
    "         * label_tensor (a 15x5 tensor) -> box tensor for one example\n",
    "       returns:\n",
    "         * classes (n,) where n is number of valid boxes\n",
    "         * boxes (n,4) where n is number of valid boxes and the 4 are ymin,xmin,ymax,xmax\n",
    "        \n",
    "    \"\"\"\n",
    "    bboxes, classes = tf.split(label_tensor, axis=1,num_or_size_splits=[4,1])\n",
    "    bmask = bboxes[:,0] > -1\n",
    "    bboxes= tf.boolean_mask(mask=bmask,tensor=bboxes)\n",
    "    \n",
    "    #zero out negative ones\n",
    "    lmask = classes > -1\n",
    "    classes = tf.boolean_mask(mask=lmask,tensor=classes)\n",
    "    classes=tf.cast(classes,dtype=tf.int64)\n",
    "    \n",
    "#     print bboxes.get_shape()\n",
    "#     print classes.get_shape()\n",
    "    return classes, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bboxes_encode(labels, bboxes, anchors,\n",
    "                  scope=None):\n",
    "    \"\"\"Encode labels and bounding boxes.\n",
    "    \"\"\"\n",
    "    return tf_ssd_bboxes_encode(\n",
    "        labels, bboxes, anchors,\n",
    "        configs[\"num_classes\"],\n",
    "        no_annotation_label=True,\n",
    "        ignore_threshold=0.5,\n",
    "        prior_scaling=configs[\"prior_scaling\"],\n",
    "        scope=scope)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_ssd_bboxes_encode(labels,\n",
    "                         bboxes,\n",
    "                         anchors,\n",
    "                         num_classes,\n",
    "                         no_annotation_label,\n",
    "                         ignore_threshold=0.5,\n",
    "                         prior_scaling=[0.1, 0.1, 0.2, 0.2],\n",
    "                         dtype=tf.float32,\n",
    "                         scope='ssd_bboxes_encode'):\n",
    "    \"\"\"Encode groundtruth labels and bounding boxes using SSD net anchors.\n",
    "    Encoding boxes for all feature layers.\n",
    "\n",
    "    Arguments:\n",
    "      labels: 1D Tensor(int64) containing groundtruth labels;\n",
    "      bboxes: Nx4 Tensor(float) with bboxes relative coordinates;\n",
    "      anchors: List of Numpy array with layer anchors;\n",
    "      matching_threshold: Threshold for positive match with groundtruth bboxes;\n",
    "      prior_scaling: Scaling of encoded coordinates.\n",
    "\n",
    "    Return:\n",
    "      (target_labels, target_localizations, target_scores):\n",
    "        Each element is a list of target Tensors.\n",
    "    \"\"\"\n",
    "    with tf.name_scope(scope):\n",
    "        target_labels = []\n",
    "        target_localizations = []\n",
    "        target_scores = []\n",
    "        for i, anchors_layer in enumerate(anchors):\n",
    "            with tf.name_scope('bboxes_encode_block_%i' % i):\n",
    "                t_labels, t_loc, t_scores = \\\n",
    "                    tf_ssd_bboxes_encode_layer(labels, bboxes, anchors_layer,\n",
    "                                               num_classes, no_annotation_label,\n",
    "                                               ignore_threshold,\n",
    "                                               prior_scaling, dtype)\n",
    "                target_labels.append(t_labels)\n",
    "                target_localizations.append(t_loc)\n",
    "                target_scores.append(t_scores)\n",
    "        return target_labels, target_localizations, target_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tf_ssd_bboxes_encode_layer(labels,\n",
    "                               bboxes,\n",
    "                               anchors_layer,\n",
    "                               num_classes,\n",
    "                               no_annotation_label,\n",
    "                               ignore_threshold=0.5,\n",
    "                               prior_scaling=[0.1, 0.1, 0.2, 0.2],\n",
    "                               dtype=tf.float32):\n",
    "    \"\"\"Encode groundtruth labels and bounding boxes using SSD anchors from\n",
    "    one layer.\n",
    "\n",
    "    Arguments:\n",
    "      labels: 1D Tensor(int64) containing groundtruth labels;\n",
    "      bboxes: Nx4 Tensor(float) with bboxes relative coordinates;\n",
    "      anchors_layer: Numpy array with layer anchors;\n",
    "      matching_threshold: Threshold for positive match with groundtruth bboxes;\n",
    "      prior_scaling: Scaling of encoded coordinates.\n",
    "\n",
    "    Return:\n",
    "      (target_labels, target_localizations, target_scores): Target Tensors.\n",
    "    \"\"\"\n",
    "    \n",
    "    #print labels\n",
    "    #print bboxes\n",
    "    # Anchors coordinates and volume.\n",
    "    ymin_ind,ymax_ind, xmin_ind,  xmax_ind = range(4)\n",
    "    \n",
    "    yref, xref, href, wref = anchors_layer\n",
    "    ymin = yref - href / 2.\n",
    "    xmin = xref - wref / 2.\n",
    "    ymax = yref + href / 2.\n",
    "    xmax = xref + wref / 2.\n",
    "    vol_anchors = (xmax - xmin) * (ymax - ymin)\n",
    "    \n",
    "    # Initialize tensors...\n",
    "    shape = (yref.shape[0], yref.shape[1], href.size)\n",
    "    feat_labels = tf.zeros(shape, dtype=tf.int64)\n",
    "    feat_scores = tf.zeros(shape, dtype=dtype)\n",
    "\n",
    "    feat_ymin = tf.zeros(shape, dtype=dtype)\n",
    "    feat_xmin = tf.zeros(shape, dtype=dtype)\n",
    "    feat_ymax = tf.ones(shape, dtype=dtype)\n",
    "    feat_xmax = tf.ones(shape, dtype=dtype)\n",
    "\n",
    "    def jaccard_with_anchors(bbox):\n",
    "        \"\"\"Compute jaccard score between a box and the anchors.\n",
    "        \"\"\"\n",
    "  \n",
    "        int_ymin = tf.maximum(ymin, bbox[ymin_ind])\n",
    "        int_xmin = tf.maximum(xmin, bbox[xmin_ind])\n",
    "        int_ymax = tf.minimum(ymax, bbox[ymax_ind])\n",
    "        int_xmax = tf.minimum(xmax, bbox[xmax_ind])\n",
    "        h = tf.maximum(int_ymax - int_ymin, 0.)\n",
    "        w = tf.maximum(int_xmax - int_xmin, 0.)\n",
    "        # Volumes.\n",
    "        inter_vol = h * w\n",
    "        union_vol = vol_anchors - inter_vol \\\n",
    "            + (bbox[ymax_ind] - bbox[ymin_ind]) * (bbox[xmax_ind] - bbox[xmin_ind])\n",
    "        jaccard = tf.div(inter_vol, union_vol)\n",
    "        return jaccard\n",
    "\n",
    "    def intersection_with_anchors(bbox):\n",
    "        \"\"\"Compute intersection between score a box and the anchors.\n",
    "        \"\"\"\n",
    "        int_ymin = tf.maximum(ymin, bbox[ymin_ind])\n",
    "        int_xmin = tf.maximum(xmin, bbox[xmin_ind])\n",
    "        int_ymax = tf.minimum(ymax, bbox[ymax_ind])\n",
    "        int_xmax = tf.minimum(xmax, bbox[xmax_ind])\n",
    "        h = tf.maximum(int_ymax - int_ymin, 0.)\n",
    "        w = tf.maximum(int_xmax - int_xmin, 0.)\n",
    "        inter_vol = h * w\n",
    "        scores = tf.div(inter_vol, vol_anchors)\n",
    "        return scores\n",
    "\n",
    "    def condition(i, feat_labels, feat_scores,\n",
    "                  feat_ymin, feat_xmin, feat_ymax, feat_xmax):\n",
    "        \"\"\"Condition: check label index.\n",
    "        \"\"\"\n",
    "        r = tf.less(i, tf.shape(labels))\n",
    "        return r[0]\n",
    "\n",
    "    def body(i, feat_labels, feat_scores,\n",
    "             feat_ymin, feat_xmin, feat_ymax, feat_xmax):\n",
    "        \"\"\"Body: update feature labels, scores and bboxes.\n",
    "        Follow the original SSD paper for that purpose:\n",
    "          - assign values when jaccard > 0.5;\n",
    "          - only update if beat the score of other bboxes.\n",
    "        \"\"\"\n",
    "        # Jaccard score.\n",
    "        label = labels[i]\n",
    "        bbox = bboxes[i]\n",
    "        jaccard = jaccard_with_anchors(bbox)\n",
    "        # Mask: check threshold + scores + no annotations + num_classes.\n",
    "        mask = tf.greater(jaccard, feat_scores)\n",
    "        # mask = tf.logical_and(mask, tf.greater(jaccard, matching_threshold))\n",
    "        mask = tf.logical_and(mask, feat_scores > -0.5)\n",
    "        mask = tf.logical_and(mask, label < num_classes)\n",
    "        imask = tf.cast(mask, tf.int64)\n",
    "        fmask = tf.cast(mask, dtype)\n",
    "        # Update values using mask.\n",
    "        feat_labels = imask * label + (1 - imask) * feat_labels\n",
    "        feat_scores = tf.where(mask, jaccard, feat_scores)\n",
    "\n",
    "        feat_ymin = fmask * bbox[ymin_ind] + (1 - fmask) * feat_ymin\n",
    "        feat_xmin = fmask * bbox[xmin_ind] + (1 - fmask) * feat_xmin\n",
    "        feat_ymax = fmask * bbox[ymax_ind] + (1 - fmask) * feat_ymax\n",
    "        feat_xmax = fmask * bbox[xmax_ind] + (1 - fmask) * feat_xmax\n",
    "\n",
    "        # Check no annotation label: ignore these anchors...\n",
    "        # interscts = intersection_with_anchors(bbox)\n",
    "        # mask = tf.logical_and(interscts > ignore_threshold,\n",
    "        #                       label == no_annotation_label)\n",
    "        # # Replace scores by -1.\n",
    "        # feat_scores = tf.where(mask, -tf.cast(mask, dtype), feat_scores)\n",
    "\n",
    "        return [i+1, feat_labels, feat_scores,\n",
    "                feat_ymin, feat_xmin, feat_ymax, feat_xmax]\n",
    "    # Main loop definition.\n",
    "    i = 0\n",
    "    [i, feat_labels, feat_scores,\n",
    "     feat_ymin, feat_xmin,\n",
    "     feat_ymax, feat_xmax] = tf.while_loop(condition, body,\n",
    "                                           [i, feat_labels, feat_scores,\n",
    "                                            feat_ymin, feat_xmin,\n",
    "                                            feat_ymax, feat_xmax],)\n",
    "    # Transform to center / size.\n",
    "    feat_cy = (feat_ymax + feat_ymin) / 2.\n",
    "    feat_cx = (feat_xmax + feat_xmin) / 2.\n",
    "    feat_h = feat_ymax - feat_ymin\n",
    "    feat_w = feat_xmax - feat_xmin\n",
    "    # Encode features.\n",
    "    feat_cy = (feat_cy - yref) / href / prior_scaling[0]\n",
    "    feat_cx = (feat_cx - xref) / wref / prior_scaling[1]\n",
    "    feat_h = tf.log(feat_h / href) / prior_scaling[2]\n",
    "    feat_w = tf.log(feat_w / wref) / prior_scaling[3]\n",
    "    # Use SSD ordering: x / y / w / h instead of ours.\n",
    "    feat_localizations = tf.stack([feat_cx, feat_cy, feat_w, feat_h], axis=-1)\n",
    "    return feat_labels, feat_localizations, feat_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    label_1 = tf.concat((tf.ones((1,4,5)), -1*tf.ones((1,11,5))),axis=1)\n",
    "  \n",
    "    label_2 = tf.concat((tf.ones((1,3,5)), -1*tf.ones((1,12,5))),axis=1)\n",
    "    label_tensor = tf.concat((label_1, label_2),axis=0)\n",
    "    feat_labels, feat_localizations, feat_scores = encode(label_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    gen = get_generator(\"tr\", batch_size=1)\n",
    "\n",
    "    im, box = gen.next()\n",
    "\n",
    "    #boxes = np.vstack(box)\n",
    "\n",
    "    #boxes= make_box_coords_relative(boxes,im_shape=(768,1152))\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    feat_labels, feat_localizations, feat_scores, labels,bboxes = encode(boxes, im_shape=(768,1152))\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        feed_dict = {bboxes:boxes[:,:4],\n",
    "                    labels:boxes[:,4]}\n",
    "        fl=sess.run(feat_labels,feed_dict=feed_dict)\n",
    "\n",
    "    print fl[0][fl[0] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def encode_one_fmap(label_tensor,feat_shape,im_shape=configs[\"tensor_input_shape\"]):\n",
    "    \"\"\"encodes one feature map size for all examples\"\"\"\n",
    "    anchors = make_anchors_for_one_fmap(img_shape=im_shape, feat_shape=feat_shape)\n",
    "    \n",
    "    num_examples_per_batch = configs[\"batch_size\"]\n",
    "    \n",
    "    all_feat_labels, all_feat_localizations, all_feat_scores = [] , [], []\n",
    "    \n",
    "    for example_ind in range(num_examples_per_batch):\n",
    "        #grab each box_coord thing\n",
    "        _, cur_label_tensor, _ = tf.split(label_tensor, num_or_size_splits=(example_ind, 1, num_examples_per_batch - example_ind -1 ))\n",
    "        cur_label_tensor = tf.squeeze(cur_label_tensor, axis=0)\n",
    "        feat_labels, feat_localizations, feat_scores = encode_one_fmap_one_example(cur_label_tensor, anchors)\n",
    "\n",
    "        \n",
    "        all_feat_labels.append(feat_labels)\n",
    "\n",
    "        all_feat_localizations.append(feat_localizations)\n",
    "        all_feat_scores.append(feat_scores)\n",
    "    \n",
    "    \n",
    "    feat_labels_tensor = tf.stack(tuple(all_feat_labels), axis=0)\n",
    "    feat_localizations_tensor = tf.stack(tuple(all_feat_localizations), axis=0)\n",
    "    feat_scores_tensor = tf.stack(tuple(all_feat_scores), axis=0)\n",
    "    \n",
    "        \n",
    "    return feat_labels_tensor, feat_localizations_tensor, feat_scores_tensor\n",
    "\n",
    "def encode_one_fmap_one_example(one_example_label_tensor, anchors):\n",
    "    classes, bboxes = encode_prep(one_example_label_tensor)\n",
    "\n",
    "    feat_labels, feat_localizations, feat_scores = tf_ssd_bboxes_encode_layer(classes,\n",
    "                                                   bboxes,\n",
    "                                                   anchors,\n",
    "                                                   num_classes=configs[\"num_classes\"],\n",
    "                                                   no_annotation_label=True,\n",
    "                                                   ignore_threshold=0.5,\n",
    "                                                   prior_scaling=configs[\"prior_scaling\"],\n",
    "                                                   dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return feat_labels, feat_localizations, feat_scores\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
