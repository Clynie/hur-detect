{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from make_anchors_orig.ipynb\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "from nbfinder import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "if __name__ == \"__main__\":\n",
    "    sys.path.append(\"../../\")\n",
    "from notebooks_src.configs import configs\n",
    "from notebooks_src.box_processing.tf_box_util import make_actual_gt_box_mask,ious_with_reference_boxes, convert_to_xyminmax, encode_to_scaled_offsets,\\\n",
    "convert_to_yxhw, make_box_coords_relative, preprocess_box_coordinates,zero_out_negatives\n",
    "import numpy as np\n",
    "from make_anchors_orig import make_anchors_dict, make_anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def match_boxes(bboxes):\n",
    "    \"\"\"bboxes: numpy array B x max_boxes x 4 box coordinates for each batch, where B is number of Batches\n",
    "                * optionally may have -1's where there is no box (unnormalized by im size)\"\"\"\n",
    "    actual_gt_box_mask = make_actual_gt_box_mask(bboxes)\n",
    "    anchors_dict = make_anchors_dict()\n",
    "    mask_dict = {fmap_shape: dict(zip([\"x_mask\", \"tp_mask\", \"num_matches\",\"actual_gt_box_mask\"],_match_boxes(bboxes, anchors,actual_gt_box_mask))) \n",
    "                                       for fmap_shape, anchors \n",
    "                                             in anchors_dict.iteritems()                \n",
    "                   \n",
    "                }\n",
    "    return mask_dict\n",
    "\n",
    "def _match_boxes(bboxes, anchors,actual_gt_box_mask, matching_threshold=0.5):\n",
    "    \"\"\"bboxes: numpy array B x max_boxes x 4 box coordinates for each batch, where B is number of Batches\n",
    "                   * 0's where no box, normalized \n",
    "       anchors_for_layer: list of 4 arrays (y,x,h,w)\n",
    "           * y and x is fm x fn x 1\n",
    "           * h and w are (M,) where M is number of anchor box shapes\"\"\"\n",
    "    aymin,  axmin, aymax, axmax = preprocess_anchors(anchors)\n",
    "    ymin,xmin, ymax, xmax = preprocess_box_coordinates(bboxes)\n",
    "    ious = ious_with_reference_boxes(reference_boxes=[aymin, aymax, axmin, axmax],axis=-1, bbox=[ymin,ymax,xmin,xmax])\n",
    "    x_mask, tp_mask = make_x_mask(ious, actual_gt_box_mask, matching_threshold)\n",
    "    num_matches = get_num_matches(x_mask)\n",
    "    return x_mask, tp_mask, num_matches, actual_gt_box_mask\n",
    "\n",
    "def get_num_matches(x_mask):\n",
    "    float_x_mask = tf.cast(x_mask,dtype=tf.float32)        \n",
    "    num_matches = tf.reduce_sum(float_x_mask)\n",
    "    return num_matches\n",
    "    \n",
    "def preprocess_anchors(anchors):\n",
    "    # anchor processing\n",
    "    ay, ax, ah, aw = anchors\n",
    "    aymin, aymax, axmin, axmax= convert_to_xyminmax(ay, ax, ah, aw)\n",
    "    #pad with two dims at end of 1\n",
    "    aymin, aymax, axmin, axmax = [np.expand_dims(np.expand_dims(tens,axis=-1), axis=-1)\\\n",
    "                                  for tens in [aymin, aymax, axmin, axmax]]\n",
    "    return aymin, axmin, aymax ,axmax\n",
    "\n",
    "def make_x_mask(ious, actual_gt_box_mask, matching_threshold):\n",
    "    max_iou_for_each_box = tf.reduce_max(ious, axis=[0,1,2])\n",
    "\n",
    "    best_box_mask = tf.greater_equal(x=ious, y=max_iou_for_each_box)\n",
    "\n",
    "    thresh_mask = tf.greater_equal(x=ious, y=matching_threshold)\n",
    "\n",
    "    tp_mask = tf.logical_or(thresh_mask, best_box_mask)\n",
    "\n",
    "    x_mask = tf.logical_and(actual_gt_box_mask, tp_mask)\n",
    "\n",
    "    x_mask = tf.transpose(x_mask, perm=[3,0,1,2,4])\n",
    "\n",
    "    #X_mask is (batch_size, y, x, num_anchors, max_boxes(15))\n",
    "    return x_mask, tp_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_make_mask_im(mask, name, num_splits, split_axis):\n",
    "    mask_ims = tf.split(mask,num_or_size_splits=num_splits, axis=split_axis)\n",
    "    for i,mask_im in enumerate(mask_ims):\n",
    "        tf.summary.image(name=name + \"_\"+ str(i),tensor=mask_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    anchors = make_anchors_dict()\n",
    "    a = preprocess_anchors(anchors[(96,144)])\n",
    "#     import h5py\n",
    "#     bbox = h5py.File(configs[\"tr_data_file\"])[\"boxes\"][7:12,:,:4]\n",
    "#     x,am= match_boxes(bbox)\n",
    "    \n",
    "#     with tf.Session() as sess:\n",
    "#         print sess.run(x[(96,144)]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
